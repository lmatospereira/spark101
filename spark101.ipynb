{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmroKx9GS/kaKNSij+CZaU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmatospereira/spark101/blob/main/spark101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O que é Apache Spark ?\n",
        "\n",
        "O Spark é um framework para processamento paralelo de dados em cluster de computadores.\n",
        "\n",
        "O que está definido em seu site oficial:\n",
        "\n",
        ">é um mecanismo multi-linguagem para executar engenharia de dados, ciência de dados, e machine learning em máquinas ou clusters de nó-único\n",
        "Apache Foudation\n",
        "\n",
        "O Spark tem diversos componentes para diferentes tipos de processamentos, todos construídos sobre o Spark Core, que é o componente que disponibiliza as funções básicas para o processamento como as funções map, reduce, filter e collect.\n",
        "\n",
        "As que mais se destacam são:\n",
        "\n",
        "* Spark SQL - é o módulo para trablahar com dados estruturados\n",
        "* Spark Streamminng - é o modulo para processamento de dados em tempo real;\n",
        "* GrpahX -  é a API para processamento de grafos em paralelo;\n",
        "* Mlib - é a blibioteca de aprendizado de máquina escalável\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/lmatospereira/spark101/blob/main/spark101_img/componetes_spark.png?raw=true\"> \n",
        "</p>\n",
        "</br>\n",
        "\n",
        "* sql: execute a Spark SQL query\n",
        "* catalog: entry point for the Catalog API for managing tables\n",
        "* read: function to read data from a file or other data source\n",
        "* conf: object to manage Spark configuration settings\n",
        "* sparkContext: entry point for core Spark API\n",
        "\n",
        "# Arquitetura do spark\n",
        "\n",
        "* **Driver Program**: este é o entry point do Spark. É onde o Spark Context é criado e é onde se define o fluxo de execução, bem como o RDD e o que deve ser executado em paralelo pelos Executores.\n",
        "* **Spark Context**: Estabelece configurações de memória e processamento dos Workers Nodes. Além disso é capaz de conectar com os diferentes tipos de Cluster Manager (além do próprio Spark Cluster Manager) como Apache Mesos ou Yarn do Hadoop.\n",
        "* **Cluster Manager**: esse é responsável por agendar e alocar um recurso computacional através do cluster.\n",
        "Worker Node: é uma máquina que contém executores e recebe as tasks do Driver Program.\n",
        "* **Executor**: é o responsável por executar as tasks.\n",
        "* **Task**: é qualquer conjunto de operações (select, joing, filter, algorítimo de machine learning, e.t.c) sobre os dados.\n",
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/lmatospereira/spark101/blob/main/spark101_img/arquitetura_spark.jpg?raw=true\"> \n",
        "</p>\n",
        "\n",
        "\n",
        "##Lazy Evaluation\n",
        "\n",
        "Lazy evaluation significa que o Spark espera até o último momento (action) para executar a sua DAG (grafo acíclico de instruções com o passo a passo). Temos dois tipos de operações que são as Actions e as Transformations.\n",
        "\n",
        "Transformation: é a operação que o RDD retorna outro RDD. Por exemplo: filtro, criação e drop de coluna, alteração de valores de uma coluna já existente.\n",
        "\n",
        "Action: é a operação que retorna um objeto que não seja um RDD. Por exemplo: count, show, collect etc.\n",
        "\n",
        "\n",
        "\n",
        "<!-- Referencias -->\n",
        "[Apache Spark](https://spark.apache.org/)\n",
        "\n",
        "[DevMedia](https://www.devmedia.com.br/introducao-ao-apache-spark/34178)\n",
        "\n",
        "[Apache Spark](https://spark.apache.org/)\n",
        "\n",
        "[Apache Spark](https://spark.apache.org/)\n",
        "\n",
        "[Apache Spark](https://spark.apache.org/)\n"
      ],
      "metadata": {
        "id": "8mFgfx5j4nM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Primeiro vamos precisar instalar uma JDK.\n",
        "2. Baixar e descompactar os arquivos do spark.\n",
        "3. Instalar o pacote findspark."
      ],
      "metadata": {
        "id": "PvwVEvMXtZ7i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTOr1mhtfTEG"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizando o import e criando e preparando as variáveis de ambiente necessárias.\n",
        "\n",
        "Com as variáveis definidas, podemos utilizar o findspark que vai permitir a importação dos pacotes necessários para utilizar o PySpark."
      ],
      "metadata": {
        "id": "so0QMgFvtQ4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n",
        "\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "SB2OSFn5heoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando a sessão do spark"
      ],
      "metadata": {
        "id": "is1zycx4tOQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructField, StringType, IntegerType, StructType, Row\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName('Spark 101') \\\n",
        "    .config('spark.ui.port', '4050') \\\n",
        "    .getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "8ySOKINahlJr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "43dfcc54-a69b-490f-d9c0-8ea6621aa4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f49f8e16750>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://04cca46e427e:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark 101</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baixando o arquivo de exemplo"
      ],
      "metadata": {
        "id": "DMx6e4HJtLh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc -q https://raw.githubusercontent.com/lmatospereira/spark101/main/beneficio.txt\n",
        "!ls -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s9n1EyLAgh-",
        "outputId": "1142e7bb-339e-4472-fcbb-7d624f5f7cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beneficio.txt\n",
            "sample_data\n",
            "spark-3.1.2-bin-hadoop2.7\n",
            "spark-3.1.2-bin-hadoop2.7.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile users.json\n",
        "{\"name\":\"Alice\", \"pcode\":\"94304\"}\n",
        "{\"name\":\"Brayden\", \"age\":30, \"pcode\":\"94304\"}\n",
        "{\"name\":\"Carla\", \"age\":19, \"pcode\":\"10036\"}\n",
        "{\"name\":\"Diana\", \"age\":46}\n",
        "{\"name\":\"Étienne\", \"pcode\":\"94104\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwDwpIcw2wPU",
        "outputId": "21c524c1-08b2-41ec-82f7-61cb1696d3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting users.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cod_sexo.json\n",
        "{\"name\":\"Masculino\", \"code\":\"1\"}\n",
        "{\"name\":\"Feminimo\", \"code\":\"2\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cESDiL5Fz6j",
        "outputId": "4d5c94c2-f852-4b45-b620-e49a1927abe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cod_sexo.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Criando um data Frame\n",
        "\n",
        "##DataFrames (Conjuntos de dados de Row objects)\n",
        "\n",
        "* O modelo dos DataFrames é semelhante a uma tabela de um RDBMS eles são representado de forma tabular.\n",
        "* Transformações são não tipadas\n",
        "  * Linhas podem conter elementos de qualquer tipo\n",
        "  * Schemas definidos não são aplicados os tipos de coluna até o tempo de execução"
      ],
      "metadata": {
        "id": "9nqu1yWR-bEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_user = spark.read.json(\"users.json\")\n",
        "\n",
        "df_cod_sexo = spark.read.json(\"cod_sexo.json\")\n",
        "\n",
        "#file = 'CupomJurosTesouroDireto.csv'\n",
        "file = 'beneficio.txt'\n",
        "df_beneficio = spark.read.csv(\n",
        "    file,\n",
        "    header=True,\n",
        "    sep = \",\"\n",
        ")"
      ],
      "metadata": {
        "id": "5qX_4LtE68vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Especificando a estrura do squema\n",
        "Alguns tipos de dados facilitam a inferência do esquema.\n",
        "\n",
        "Muitas vezes tem que definir o esquema você mesmo.\n",
        "\n",
        "Spark tem ferramentas para ajudar a especificar a estrutura\n",
        "em seguida, precisamos criar a lista de campos de estrutura\n",
        "\n",
        "|Exemplo|\n",
        "|---|\n",
        "|:param name: string, nome do campo|\n",
        "|:param dataType: :class:DataType do campo|\n",
        "|:param nullable: boolean, se o campo pode ser nulo (Nenhum)|\n",
        "\n",
        "[sql-ref-datatypes](https://spark.apache.org/docs/latest/sql-ref-datatypes.html)\n",
        "\n"
      ],
      "metadata": {
        "id": "DkjgsiDEGhUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_list = [\n",
        "    StructField(\"ano\", StringType()),\n",
        "    StructField(\"tipo_beneficio\", StringType()),\n",
        "    StructField(\"grupo_idade\", StringType()),\n",
        "    StructField(\"sexo\", StringType()),\n",
        "    StructField(\"tipo_cliente\", StringType()),\n",
        "    StructField(\"qtd_beneficio\", IntegerType()),\n",
        "    StructField(\"grupo_especie\", StringType())\n",
        "]\n",
        "\n",
        "new_schema = StructType(columns_list)\n",
        "\n",
        "df2_beneficio = spark.read.csv(\n",
        "    file,\n",
        "    schema=new_schema,\n",
        "    header=True,\n",
        "    sep = \",\"\n",
        ")\n",
        "\n",
        "Schema = Row(\"id\",\"setor\")\n",
        "dados_teste = [\n",
        "    Schema(1, \"vendas\"),\n",
        "    Schema(2,\"TI\"),\n",
        "    Schema(3,'RH')\n",
        "]\n",
        "\n",
        "df_teste = spark.createDataFrame(\n",
        "    data=dados_teste\n",
        ")\n",
        "\n",
        "\n",
        "print(f'Schema do dataframe: df_beneficio')\n",
        "df_beneficio.printSchema()\n",
        "\n",
        "print(f'Schema do dataframe: df2_beneficio')\n",
        "df2_beneficio.printSchema()\n",
        "\n",
        "print(f'Schema do dataframe: df_teste')\n",
        "df_teste.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j7lmTYqIYeE",
        "outputId": "be05d8dc-7886-4d85-9ca5-d99f274a8f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema do dataframe: df_beneficio\n",
            "root\n",
            " |-- Ano: string (nullable = true)\n",
            " |-- Especie de Beneficio: string (nullable = true)\n",
            " |-- Grupos de Idade Cessacao: string (nullable = true)\n",
            " |-- Sexo: string (nullable = true)\n",
            " |-- Clientela: string (nullable = true)\n",
            " |-- Quantidade Beneficios Cessados: string (nullable = true)\n",
            " |-- Grupo/Principais Especies: string (nullable = true)\n",
            "\n",
            "Schema do dataframe: df2_beneficio\n",
            "root\n",
            " |-- ano: string (nullable = true)\n",
            " |-- tipo_beneficio: string (nullable = true)\n",
            " |-- grupo_idade: string (nullable = true)\n",
            " |-- sexo: string (nullable = true)\n",
            " |-- tipo_cliente: string (nullable = true)\n",
            " |-- qtd_beneficio: integer (nullable = true)\n",
            " |-- grupo_especie: string (nullable = true)\n",
            "\n",
            "Schema do dataframe: df_teste\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- setor: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Existem dois tipos principais de operações DataFrame\n",
        "\n",
        "##Ações com Data Frame (action)\n",
        "* Ações de saída de valores de dados do DataFrame\n",
        "  * A saída é normalmente retornada dos executores para o Spark principal\n",
        "programa (chamado de driver) ou salvo em um arquivo"
      ],
      "metadata": {
        "id": "z_6WZuxs40xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"count: retorna o número de linhas​\")\n",
        "df_beneficio.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCrq93Nfmfk8",
        "outputId": "a7c2576c-e402-4124-9b72-fe697eb995bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: retorna o número de linhas​\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42031"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"first: retorna a primeira linha (sinônimo de head())\")\n",
        "df_beneficio.first()"
      ],
      "metadata": {
        "id": "O4se67MlAJ_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"take(n): retorna as primeiras n linhas como um array (sinônimo de head(n))\")\n",
        "df_beneficio.take(1)"
      ],
      "metadata": {
        "id": "ZlpE9i-LALaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"collect: retorna todas as linhas do DataFrame como um array​\")\n",
        "df_beneficio.collect()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpb0IxjJARFG",
        "outputId": "3e01fa62-bd12-4da4-e61e-4efa04431182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collect: retorna todas as linhas do DataFrame como um array​\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(Ano='1997', Especie de Beneficio='Ap Tempo Contribuição Det Ignorado', Grupos de Idade Cessacao='25 a 29 Anos', Sexo='Masculino', Clientela='Urbana', Quantidade Beneficios Cessados='0', Grupo/Principais Especies='Ap Tempo Contrib Det Ignorado')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"show(n): exibe as primeiras n linhas em forma de tabela (o padrão é 20 linhas)​\")\n",
        "df_beneficio.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0GgGU9_mnva",
        "outputId": "23069a38-7949-4a6f-b1e4-935bc3e9bda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "show(n): exibe as primeiras n linhas em forma de tabela (o padrão é 20 linhas)​\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "| Ano|Especie de Beneficio|Grupos de Idade Cessacao|     Sexo|Clientela|Quantidade Beneficios Cessados|Grupo/Principais Especies|\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "|1997|Ap Tempo Contribu...|            25 a 29 Anos|Masculino|   Urbana|                             0|     Ap Tempo Contrib ...|\n",
            "|1997|Ap Tempo Contribu...|            25 a 29 Anos| Feminino|   Urbana|                             0|     Ap Tempo Contrib ...|\n",
            "|1997|Ap Tempo Contribu...|            25 a 29 Anos| Ignorado|   Urbana|                             0|     Ap Tempo Contrib ...|\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformations\n",
        "\n",
        "* As transformações criam um novo DataFrame baseado em um existente\n",
        "  * O novo DataFrame pode ter o mesmo esquema ou um diferente\n",
        "* As transformações não retornam nenhum valor ou dado ao driver\n",
        "  * Os dados permanecem distribuídos entre os executores do aplicativo  \n",
        "* DataFrames são imutáveis\n",
        "  * Os dados em um DataFrame nunca são modificados\n",
        "  * Use transformações para criar um novo DataFrame com os dados que você precisa"
      ],
      "metadata": {
        "id": "6FYmbQDBBCnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"select: seleciona apenas as colunas especificadas são incluídas\")\n",
        "df = df_beneficio.select('Ano')\n",
        "\n",
        "df.show(1)\n",
        "\n",
        "df = df_beneficio.select('Sexo')\n",
        "df.show(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xetd2RnUBAte",
        "outputId": "2cc6fdaf-835b-41b0-e964-fbfb23528468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select: seleciona apenas as colunas especificadas são incluídas\n",
            "+----+\n",
            "| Ano|\n",
            "+----+\n",
            "|1997|\n",
            "+----+\n",
            "only showing top 1 row\n",
            "\n",
            "+---------+\n",
            "|     Sexo|\n",
            "+---------+\n",
            "|Masculino|\n",
            "+---------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"where: Filtra apenas as linhas em que a expressão especificada é verdadeira são incluídas (sinônimo de filter)\")\n",
        "df_beneficio.where('Ano > 1997').show(3)\n",
        "df_beneficio.where(\"Sexo == 'Masculino'\").show(3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgc6os9LEYCD",
        "outputId": "b740955b-987f-41ef-c4e7-42ce62ebda58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "where: Filtra apenas as linhas em que a expressão especificada é verdadeira são incluídas (sinônimo de filter)\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "| Ano|Especie de Beneficio|Grupos de Idade Cessacao|     Sexo|Clientela|Quantidade Beneficios Cessados|Grupo/Principais Especies|\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "|1998|Ap Tempo Contribu...|            25 a 29 Anos|Masculino|   Urbana|                             0|     Ap Tempo Contrib ...|\n",
            "|1998|Ap Tempo Contribu...|            25 a 29 Anos| Feminino|   Urbana|                             0|     Ap Tempo Contrib ...|\n",
            "|1998|Ap Tempo Contribu...|            25 a 29 Anos| Ignorado|   Urbana|                             0|     Ap Tempo Contrib ...|\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "| Ano|Especie de Beneficio|Grupos de Idade Cessacao|     Sexo|Clientela|Quantidade Beneficios Cessados|Grupo/Principais Especies|\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "|1997|Ap Tempo Contribu...|            25 a 29 Anos|Masculino|   Urbana|                             0|     Ap Tempo Contrib ...|\n",
            "|1997|Ap Tempo Contribu...|            30 a 34 Anos|Masculino|   Urbana|                            10|     Ap Tempo Contrib ...|\n",
            "|1997|Ap Tempo Contribu...|            35 a 39 Anos|Masculino|   Urbana|                           249|     Ap Tempo Contrib ...|\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"orderBy: Ordena as  as linhas são classificadas pela(s) coluna(s) especificada(s) (sinônimo de sort)\")\n",
        "df_beneficio.orderBy('Ano').show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbM72jQvEahu",
        "outputId": "c6eae644-aea7-43a1-a161-4a8c8bc94411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orderBy: Ordena as  as linhas são classificadas pela(s) coluna(s) especificada(s) (sinônimo de sort)\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "| Ano|Especie de Beneficio|Grupos de Idade Cessacao|     Sexo|Clientela|Quantidade Beneficios Cessados|Grupo/Principais Especies|\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "|   -|                   -|                       -|        -|        -|                             -|                     null|\n",
            "|1991|Acidentários Det ...|             Até 19 Anos|Masculino|    Rural|                            59|     Benefícios Aciden...|\n",
            "|1991|Acidentários Det ...|             Até 19 Anos| Feminino|    Rural|                             4|     Benefícios Aciden...|\n",
            "+----+--------------------+------------------------+---------+---------+------------------------------+-------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"join: junta dois DataFrames na(s) coluna(s) especificada(s)\")\n",
        "\n",
        "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
        "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
        "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
        "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
        "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
        "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
        "  ]\n",
        "\n",
        "dept = [(\"Finance\",10), \\\n",
        "    (\"Marketing\",20), \\\n",
        "    (\"Sales\",30), \\\n",
        "    (\"IT\",40) \\\n",
        "  ]\n",
        "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
        "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
        "\n",
        "deptColumns = [\"dept_name\",\"dept_id\"]\n",
        "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
        "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
        "\n",
        "df = empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\")\n",
        "\n",
        "df.show(10)"
      ],
      "metadata": {
        "id": "UYPBq2oiEc0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c53cded-3401-4a1f-dbe0-f11f3fd7d503"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "join: junta dois DataFrames na(s) coluna(s) especificada(s)\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
            "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
            "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
            "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
            "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"limit(n): cria um novo DataFrame com apenas as primeiras n linhas\")\n",
        "\n",
        "\n",
        "df = df_beneficio.limit(10)\n",
        "\n",
        "df.count()"
      ],
      "metadata": {
        "id": "0XMfoU6lEfFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650726cb-23ac-40a3-a10d-b6134cb8d954"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "limit(n): cria um novo DataFrame com apenas as primeiras n linhas\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}